model,sparsity,task,fine-tuning,accuracy,perplexity,samples_per_second
GPT2,0,lm,0,0.3791,30.6306,72.09
GPT2,0,lm,1,0.4225,21.561,71.837
GPT2,0.1,lm,0,0.3764,31.1309,52.379
GPT2,0.1,lm,1,0.422,21.6392,71.68
GPT2,0.5,lm,0,0.0192,8015.4958,55.498
GPT2,0.5,lm,1,0.3653,34.731,71.52
GPT2,0.9,lm,0,0.0016,5893.6237,68.514
GPT2,0.9,lm,1,0.127,830.6939,71.503
GPT2,0.95,lm,0,0.0296,6843.6378,60.012
GPT2,0.95,lm,1,0.0734,1448.0163,71.749
GPT2,0.99,lm,0,0.0415,15580.0809,54.748
GPT2,0.99,lm,1,0.069,1724.3949,59.686
Roberta,0.0,lm,1,0.9884,1.0370,106.936
Roberta,0.1,lm,0,0.0,51605758,62.186
Roberta,0.1,lm,1,0.9976,1.0212,108.02
Roberta,0.5,lm,1,0.9782,1.1472,108.137
Roberta,0.9,lm,1,0.53078,20.4651,106.908
Roberta,0.95,lm,1,0.2743,197.1214,107.309
Roberta,0.99,lm,1,0.1752,539.4706,107.815
Pegasus,0.0,lm,1,0.0116,1.002,39.676
Pegasus,0.1,lm,0,0.0621,5159.6648,27.934
Pegasus,0.1,lm,1,0.0117,1.0064,37.764
Pegasus,0.5,lm,0,0.0723,206.4585,26.133
Pegasus,0.5,lm,1,0.0116,1.00,44.871
Pegasus,0.9,lm,1,0.0391,23.2615,44.999
Pegasus,0.95,lm,1,0.0402,477.499,38.232
Pegasus,0.99,lm,1,0.0557,922.1249,44.829
GPT2,0,mrpc,1,0.7304,,1048.527
GPT2,0.1,mrpc,1,0.7279,,1554.038
GPT2,0.5,mrpc,1,0.6814,,1200.707
GPT2,0.9,mrpc,1,0.6838,,1136.135
GPT2,0.95,mrpc,1,0.6397,,1586.716
GPT2,0.99,mrpc,1,0.6838,,1655.091
Roberta,0,mrpc,1,0.8725,,472.472
Roberta,0.1,mrpc,1,0.8701,,487.849
Roberta,0.5,mrpc,1,0.6838,,571.759
Roberta,0.9,mrpc,1,0.6838,,555.136
Roberta,0.95,mrpc,1,0.6838,,555.136
Roberta,0.99,mrpc,1,0.6838,,500.116